## 什么是fine-tuning
给pre-trained的model添加一些capability，而不是外挂knowledge，这些capability是包含在model内部的，但是需要注意，增加了外部的能力，极有可能原有的能力会下降。
![[CleanShot 2024-08-15 at 11.11.47.png]]
这里要区分一下从零开始训练模型和微调模型对于数据的要求，通常微调模型对数据要求特别低，只需要输入和输出组成的数据对即可，因为pre-trained llm已经具备理解的能力，而训练一个pre-trained模型则需要更多的原始数据、标注和特征，两者对数据的要求完全不同。
微调支持同时加强多种类型的能力。
## 什么时候需要Fine-tuning
首先来看一下大模型项目pipeline：
![[CleanShot 2024-08-15 at 10.33.24.png]]
如果通过Prompt engineering可以解决问题，那就不要进行Fine-tuning，比如采用Few-shot或者Cot等方法
![[CleanShot 2024-08-15 at 11.00.33.png]]
但采用Few-shot存在的问题是：
1.例子太多，比如task需要判断类别，类别的样本包含20种，那few-shot至少需要20个。
2.即使传递了大于20的样本，有可能效果还是不佳。
如果在遇到上面的问题时，就可以考虑使用fine-tuning，但优先考虑一定还是使用few-shot或者cot。
## Fine-tune流程
![[CleanShot 2024-08-15 at 14.51.45.png]]
### 数据构造
数据均需要成prompt的形式<input,output>
数据集包含训练集、验证集和测试集，验证集在训练的时候验证，测试集用于测试微调好的model
验证就相当于一个学生平时的各种模拟考试，而测试则是最终的高考，测试集在训练时不可见。
### 模型遗忘
微调之后，大模型原本的能力丢失，比如微调增加情感分析能力，但是原本的正常问题，回答都会加上positive或negative。
解决思路：
1.不解决，反正拥有想要的能力即可
2.使用更大的model，微调的数据微不足道，对原本model的影响就非常小
3.缺啥补啥，哪个能力丢失了，就再微调以下这方面的能力
### 选择模型
微调使用的开源模型选择很多，通常要根据硬件水平、模型能力等来综合选择。
当然可以同时微调多个模型，来综合对比哪个pre-trained model效果更好。
### 分析模型
在选择model的过程中，我们要判断这些model缺乏哪些能力，也就是gap，model的answer和我们目标的差距，了解gap之后，再根据gap来进行数据收集和fine tune，而不是上来就直接进行fine tune。
### 微调方式
1.全量微调：所有参数都调一遍，影响范围大，不推荐使用
2.freeze微调：不推荐使用
3.lora微调：推荐使用
## Lora
![[CleanShot 2024-08-15 at 14.57.11.png]]
通常在使用lora微调时，会将原本的参数冻结，不参与梯度更新。
lora微调之后，需要和原本的参数进行合并。
常见lora微调框架：
LLAMA-Factory：国产，支持一键微调各种国内国外的框架，[GitHub - hiyouga/LLaMA-Factory: A WebUI for Efficient Fine-Tuning of 100+ LLMs (ACL 2024)](https://github.com/hiyouga/LLaMA-Factory?tab=readme-ov-file)
GLM和Qwen：github的页面直接就有微调，并且也封装了一键微调的工具，按照要求的数据集格式准备好数据，直接运行就可以微调。
## 微调参数
常用微调参数：
量化等级：int4、int8、fp16、bf16(比fp16精度更高，需要一些硬件支持)
提示模板：不同的模型可能模板样式不一样
RoPE插值方法：linear和dynamic
加速方式：flashattn和unsloth
## 微调案例
自己用代码手动微调Mistra7B：
文档介绍： [Fine-tuning Falcon-7b-instruct using PEFT- LoRA on Free GPU | by Srishti Nagu | Medium](https://medium.com/@srishtinagu19/fine-tuning-falcon-7b-instruct-using-peft-lora-on-free-gpu-6fa1b0fcbcb)
在线调试： [Google Colab](https://colab.research.google.com/drive/1pAOYaaVZWY5abusxw9ar3uXiTobK-8mi?usp=sharing#scrollTo=C0xjesvvgWrz)