## 简单生成原理
![[CleanShot 2024-07-18 at 08.37.32.png]]
![[CleanShot 2024-07-18 at 08.38.21.png]]
Seq2Seq：全称为Sequence-to-Sequence，是一种深度学习模型，将一个序列转化为另一个序列，比如输入到输出。
简单来讲，Transformer模型，就是你输入一个词、句子，其可以根据Transformer内部的各种操作，给你接出来后面应该接什么，就类似于我们学英语培养语感，当掌握的知识足够多足够熟练后，听到前面说的是什么，自动就知道该怎么接，就算这时候并不知道具体含义是什么。
## 大模型训练-简单原理
![[CleanShot 2024-07-18 at 08.46.31.png]]
模型训练包括：全量训练和微调，微调就是在已有的模型底座上增加一些额外的数据。
![[CleanShot 2024-07-18 at 08.48.29.png]]
![[CleanShot 2024-07-18 at 08.49.06.png]]
如果基于已有的模型来解决，就是通过Prompt提示词工程，或者知识图谱、RAG等技术。
![[CleanShot 2024-07-18 at 08.50.08.png]]
另外一种方式是训练私有模型，主要流程如上图，其中在数据集设计过程中，一个重点是数据配比，通用数据和行业数据，重点知识数据的配比，这往往是决定模型效果的关键点。
### 具体训练过程
### 预训练模型
![[CleanShot 2024-07-18 at 10.50.23.png]]
一个基础的ChatGLM-7b-Base，预计需要最少100张卡，一般来讲，需要40-50个节点(8张卡一个节点)跑一两周来训练。
预训练模型只训练了大量的知识库，但是并未针对训练对话，所以本质上只是底座，回答问题的效果是非常差的，所以需要微调，就比如刚出大学的大学生到了公司，无论能力多强，肯定还需要学习和适应。
### 微调
![[CleanShot 2024-07-18 at 10.51.25.png]]
要注意的是，微调并不微，需要对整个数据集的每个token都进行微调，所以需要采用LoRA之类的技术，来只对需要的token进行微调，这也更符合实际，不影响不相关的内容。
其中有一类微调模型instrct，表示可以根据用户的需要来回答，比如按照json格式返回。
### 强化学习
![[CleanShot 2024-07-18 at 10.53.30.png]]
强化学习(aligment)：一个人有基础知识，又进行了业务培训，但是不按照套路出牌，自己喜欢瞎搞，再给他设定一些规范，这就是强化学习。
注意这张图后面部分是RAG：这也是强化学习，比如要求大模型严格按照知识库回答问题。